/home/cike/anaconda3/envs/pymarl2/lib/python3.7/site-packages/gym/logger.py:34: UserWarning: [33mWARN: Overriding environment Overcooked-v0[0m
  warnings.warn(colorize("%s: %s" % ("WARN", msg % args), "yellow"))
/home/cike/anaconda3/envs/pymarl2/lib/python3.7/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  "Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 "
2024-12-12 13:13:54,270 - INFO - Starting.
2024-12-12 13:13:54,270 - INFO - Loading Data.
2024-12-12 13:29:15,818 - INFO - Data loaded in 0.0 hours 15.0 minutes.
2024-12-12 13:29:15,919 - INFO - Training Started.
/home/cike/marl_collector/adhoc_dt/envs/overcooked/overcooked_ai
/home/cike/marl_collector/src/envs/overcooked/overcooked_ai
pygame 2.6.1 (SDL 2.28.4, Python 3.7.12)
Hello from the pygame community. https://www.pygame.org/contribute.html
Epoch 1/100:   0%|          | 0/7 [00:00<?, ?it/s]Epoch 1/100:   0%|          | 0/7 [00:48<?, ?it/s]
Traceback (most recent call last):
  File "train_dt.py", line 172, in <module>
    model_save_path=config["model_save_path"])
  File "train_dt.py", line 35, in train_model
    loss_dt = trainer_dt.train(episodes_data, device=device, max_ep_len=episodes_data["state"].size(1), max_len=K)
  File "/home/cike/marl_collector/adhoc_dt/Trainer/Trainer.py", line 1036, in train
    loss = self.train_step(episodes_data, device, max_ep_len, max_len)
  File "/home/cike/marl_collector/adhoc_dt/Trainer/Trainer.py", line 1049, in train_step
    states, actions, rtg, timesteps, attention_mask=attention_mask,
  File "/home/cike/marl_collector/adhoc_dt/Networks/dt_models/rtg_dt.py", line 97, in forward
    attention_mask=stacked_attention_mask,
  File "/home/cike/anaconda3/envs/pymarl2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/cike/marl_collector/adhoc_dt/Networks/dt_models/trajectory_gpt2.py", line 741, in forward
    output_attentions=output_attentions,
  File "/home/cike/anaconda3/envs/pymarl2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/cike/marl_collector/adhoc_dt/Networks/dt_models/trajectory_gpt2.py", line 334, in forward
    feed_forward_hidden_states = self.mlp(self.ln_2(hidden_states))
  File "/home/cike/anaconda3/envs/pymarl2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/cike/marl_collector/adhoc_dt/Networks/dt_models/trajectory_gpt2.py", line 257, in forward
    h = self.act(self.c_fc(x))
  File "/home/cike/anaconda3/envs/pymarl2/lib/python3.7/site-packages/torch/nn/functional.py", line 1457, in relu
    result = torch.relu(input)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.88 GiB (GPU 0; 47.46 GiB total capacity; 9.99 GiB already allocated; 1.41 GiB free; 10.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
